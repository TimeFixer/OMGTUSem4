{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b897e77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1146\n",
      "[LightGBM] [Info] Number of data points in the train set: 8630, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 3930.343337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "import os\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "raw_data = pd.read_csv('old_dataset.csv')\n",
    "raw_data = raw_data.drop(['Unnamed: 0'], axis=1)\n",
    "y = raw_data['price']\n",
    "X = raw_data.drop(['price'], axis=1)\n",
    "\n",
    "categorical_cols = ['cut', 'color', 'clarity']\n",
    "numerical_cols = ['carat', 'depth', 'table', 'x', 'y', 'z']\n",
    "\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('encoder_scaler', ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OrdinalEncoder(categories=[\n",
    "                ['Fair', 'Good', 'Very Good', 'Premium', 'Ideal'],  # cut\n",
    "                ['J', 'I', 'H', 'G', 'F', 'E', 'D'],                # color\n",
    "                ['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF']  # clarity\n",
    "            ]), categorical_cols),\n",
    "            ('num', MinMaxScaler(), numerical_cols)\n",
    "        ]\n",
    "    ))\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "poly_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('lin_reg', LinearRegression())\n",
    "])\n",
    "poly_pipeline.fit(X_train, y_train)\n",
    "with open(f'models\\\\PolynomialFeatures.pkl','wb') as f:\n",
    "      pickle.dump(poly_pipeline, f)\n",
    "\n",
    "dt_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('dt', BaggingRegressor(n_estimators=10,max_samples=0.8, random_state=42,n_jobs=-1))\n",
    "])\n",
    "dt_pipeline.fit(X_train, y_train)\n",
    "with open(f'models\\\\BaggingRegressor.pkl','wb') as f:\n",
    "      pickle.dump(dt_pipeline, f)\n",
    "\n",
    "\n",
    "X_train_preprocessed = preprocessing_pipeline.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessing_pipeline.transform(X_test)\n",
    "\n",
    "dt_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('dt', GradientBoostingRegressor(n_estimators=20, learning_rate=0.1, max_depth=3, random_state=42))\n",
    "])\n",
    "dt_pipeline.fit(X_train, y_train)\n",
    "with open(f'models\\\\GradientBoostingRegressor.pkl','wb') as f:\n",
    "      pickle.dump(dt_pipeline, f)\n",
    "\n",
    "poly_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('stacking_reg', StackingRegressor(\n",
    "        estimators=[\n",
    "            ('dt', DecisionTreeRegressor(max_depth=14, min_samples_split=7, min_samples_leaf=7, random_state=42)),\n",
    "            ('lr', LinearRegression())\n",
    "        ],\n",
    "        final_estimator=LinearRegression()\n",
    "    ))\n",
    "])\n",
    "    \n",
    "poly_pipeline.fit(X_train, y_train)\n",
    "with open(f'models\\\\StackingRegressor.pkl','wb') as f:\n",
    "      pickle.dump(poly_pipeline, f)\n",
    "\n",
    "\n",
    "poly_pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing_pipeline),\n",
    "    ('lgbm', lgb.LGBMRegressor(n_estimators=100))\n",
    "])\n",
    "\n",
    "poly_pipeline.fit(X_train, y_train)\n",
    "\n",
    "with open('models\\\\lightgbm.pkl', 'wb') as f:\n",
    "    pickle.dump(poly_pipeline, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
