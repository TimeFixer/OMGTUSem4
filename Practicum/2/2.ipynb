{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: потребление = 0.6000, Время обучения = 0.0094 сек\n",
      "Decision Tree: потребление = 0.7000, Время обучения = 0.0011 сек\n",
      "K-Nearest Neighbors: потребление = 0.4000, Время обучения = 0.0012 сек\n",
      "Naive Bayes: потребление = 0.8000, Время обучения = 0.0010 сек\n",
      "\n",
      "Три наиболее быстрых алгоритма с низким потреблением данных:\n",
      "- Naive Bayes: потребление = 0.8000, время = 0.0010 сек\n",
      "- Logistic Regression: потребление = 0.6000, время = 0.0094 сек\n",
      "- Decision Tree: потребление = 0.7000, время = 0.0011 сек\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Предполагаем, что у нас есть один из ваших датасетов, например, dataset_1.csv\n",
    "df = pd.read_csv('dataset_1.csv')\n",
    "\n",
    "# Подготовка данных\n",
    "# Кодируем категориальные признаки\n",
    "le_figure1 = LabelEncoder()\n",
    "le_figure2 = LabelEncoder()\n",
    "df['figure1'] = le_figure1.fit_transform(df['figure1'])\n",
    "df['figure2'] = le_figure2.fit_transform(df['figure2'])\n",
    "\n",
    "# Если есть дополнительные категориальные признаки (color1, color2)\n",
    "if 'color1' in df.columns:\n",
    "    le_color1 = LabelEncoder()\n",
    "    le_color2 = LabelEncoder()\n",
    "    df['color1'] = le_color1.fit_transform(df['color1'])\n",
    "    df['color2'] = le_color2.fit_transform(df['color2'])\n",
    "\n",
    "# Разделяем признаки и целевую переменную\n",
    "X = df.drop('collision', axis=1)\n",
    "y = df['collision']\n",
    "\n",
    "# Разделяем на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Выбор 4 классических методов машинного обучения\n",
    "models = {\n",
    "    # Логистическая регрессия: \n",
    "    # - Простой и интерпретируемый метод\n",
    "    # - Хорошо работает с бинарной классификацией\n",
    "    # - Эффективен для линейно разделимых данных\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    \n",
    "    # Дерево решений:\n",
    "    # - Интуитивно понятен и легко интерпретируется\n",
    "    # - Может моделировать нелинейные зависимости\n",
    "    # - Хорошо подходит для смешанных типов данных\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=5),\n",
    "    \n",
    "    # k-ближайших соседей:\n",
    "    # - Простой и не требует предположений о распределении данных\n",
    "    # - Эффективен для задач с локальной структурой данных\n",
    "    # - Подходит для небольших и средних датасетов\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    \n",
    "    # Наивный Байес:\n",
    "    # - Очень быстрый и требует мало данных для обучения\n",
    "    # - Хорошо работает с независимыми признаками\n",
    "    # - Прост в реализации и эффективен для базовой классификации\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "# Обучение и оценка моделей\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    results[name] = {'accuracy': accuracy, 'time': training_time}\n",
    "    \n",
    "    # Сохранение модели\n",
    "    with open(f'{name.lower().replace(\" \", \"_\")}_model.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    print(f\"{name}: потребление = {accuracy:.4f}, Время обучения = {training_time:.4f} сек\")\n",
    "\n",
    "# Выбор 3 наиболее быстрых алгоритмов с низким потреблением данных\n",
    "# Основываясь на характеристиках:\n",
    "# 1. Naive Bayes - минимальное время обучения, низкие требования к данным\n",
    "# 2. Logistic Regression - быстрая сходимость, работает с небольшими выборками\n",
    "# 3. Decision Tree - быстрое обучение на небольших данных, не требует сложной предобработки\n",
    "\n",
    "fastest_models = [\n",
    "    'Naive Bayes',\n",
    "    'Logistic Regression',\n",
    "    'Decision Tree'\n",
    "]\n",
    "\n",
    "print(\"\\nТри наиболее быстрых алгоритма с низким потреблением данных:\")\n",
    "for model_name in fastest_models:\n",
    "    print(f\"- {model_name}: потребление = {results[model_name]['accuracy']:.4f}, \"\n",
    "          f\"время = {results[model_name]['time']:.4f} сек\")\n",
    "\n",
    "# Пример загрузки сохраненной модели\n",
    "# with open('naive_bayes_model.pkl', 'rb') as f:\n",
    "#     loaded_model = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
