{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1, y1, x2, y2):\n",
    "    return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "\n",
    "def get_circle_radius(circle_size):\n",
    "    return math.sqrt(circle_size/math.pi)\n",
    "\n",
    "def get_square_half_side(size):\n",
    "    return math.sqrt(size) / 2\n",
    "\n",
    "def check_circle_square_collision(circle_x, circle_y, circle_size,\n",
    "                                square_x, square_y, square_size): \n",
    "    \n",
    "    # Вычисляем радиус круга и половину стороны квадрата\n",
    "    radius = get_circle_radius(circle_size)\n",
    "    half_side = get_square_half_side(square_size)\n",
    "    \n",
    "    # Находим ближайшую точку квадрата к центру круга\n",
    "    closest_x = max(square_x - half_side, min(circle_x, square_x + half_side))\n",
    "    closest_y = max(square_y - half_side, min(circle_y, square_y + half_side))\n",
    "    \n",
    "    # Вычисляем расстояние от центра круга до ближайшей точки\n",
    "    dist = distance(circle_x, circle_y, closest_x, closest_y)\n",
    "    \n",
    "    # Если расстояние меньше радиуса, есть коллизия\n",
    "    return dist < radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collision(obj1, obj2):\n",
    "    if obj1['figure'] == 'circle' and obj2['figure'] == 'circle':\n",
    "        return (distance(obj1['x'], obj2['x'], obj1['y'], obj2['y']) < get_circle_radius(obj1['size']) + get_circle_radius(obj2['size']))\n",
    "    \n",
    "    elif obj1['figure'] == 'rectangle' and obj2['figure'] == 'rectangle':\n",
    "        return (abs(obj1['x'] - obj2['x']) < (get_square_half_side(obj1['size'])) + get_square_half_side(obj2['size'])) and abs(obj1['y'] - obj2['y']) < (get_square_half_side(obj1['size'])) + get_square_half_side(obj2['size'])\n",
    "        \n",
    "    elif (obj1['figure'] in ('rectangle', 'circle') and \n",
    "        obj2['figure'] in ('rectangle', 'circle') and \n",
    "        obj1['figure'] != obj2['figure']):\n",
    "        # Определяем, какой объект круг, а какой прямоугольник\n",
    "        circle_obj = obj1 if obj1['figure'] == 'circle' else obj2\n",
    "        rect_obj = obj2 if obj1['figure'] == 'circle' else obj1\n",
    "        \n",
    "        # Создаем кортежи с нужными данными\n",
    "        circle = (circle_obj['x'], circle_obj['y'], get_circle_radius(circle_obj['size']))\n",
    "        square = (rect_obj['x'], rect_obj['y'], rect_obj['size'])\n",
    "            \n",
    "        result = check_circle_square_collision(circle[0], circle[1], circle[2],\n",
    "                                            square[0], square[1], square[2])\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_object():\n",
    "    return {\n",
    "        'x': random.randint(-5, 5),\n",
    "        'y': random.randint(-6, 6),\n",
    "        'size': random.randint(10, 100),\n",
    "        'figure': random.choice(['circle', 'rectangle']),\n",
    "\n",
    "        'is_active': random.choice([0, 1]),  \n",
    "        'color': random.choice(['red', 'blue', 'green', 'yellow']), \n",
    "        'priority': random.choice([1, 2, 3, 4, 5]),  \n",
    "        \n",
    "        'speed': random.uniform(0, 10),  \n",
    "        'opacity': random.uniform(0, 1),  \n",
    "        'rotation': random.randint(0, 359)  \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(num_rows, num_features=4):\n",
    "    # Определяем полный набор колонок\n",
    "    all_columns = [\n",
    "        'x1', 'y1', 'size1', 'figure1',  \n",
    "        'is_active1', 'color1', 'priority1', 'speed1', 'opacity1', 'rotation1',  \n",
    "        'x2', 'y2', 'size2', 'figure2',  \n",
    "        'is_active2', 'color2', 'priority2', 'speed2', 'opacity2', 'rotation2',  \n",
    "        'collision'  \n",
    "    ]\n",
    "    \n",
    "    # Выбираем нужное количество признаков (исключая collision)\n",
    "    if num_features == 4:\n",
    "        selected_columns = ['x1', 'y1', 'size1', 'figure1', \n",
    "                          'x2', 'y2', 'size2', 'figure2', 'collision']\n",
    "    elif num_features == 7:\n",
    "        selected_columns = ['x1', 'y1', 'size1', 'figure1', 'is_active1', 'color1', 'priority1',\n",
    "                          'x2', 'y2', 'size2', 'figure2', 'is_active2', 'color2', 'priority2', 'collision']\n",
    "    else:  # 10 признаков\n",
    "        selected_columns = all_columns\n",
    "\n",
    "    df = pd.DataFrame(columns=selected_columns)\n",
    "    \n",
    "    for i in range(num_rows):\n",
    "        obj1 = generate_random_object()\n",
    "        obj2 = generate_random_object()\n",
    "        \n",
    "        # Создаем словарь с данными для строки\n",
    "        row_data = {\n",
    "            'x1': obj1['x'], 'y1': obj1['y'], 'size1': obj1['size'], 'figure1': obj1['figure'],\n",
    "            'x2': obj2['x'], 'y2': obj2['y'], 'size2': obj2['size'], 'figure2': obj2['figure'],\n",
    "            'is_active1': obj1['is_active'], 'color1': obj1['color'], \n",
    "            'priority1': obj1['priority'], 'speed1': obj1['speed'],\n",
    "            'opacity1': obj1['opacity'], 'rotation1': obj1['rotation'],\n",
    "            'is_active2': obj2['is_active'], 'color2': obj2['color'],\n",
    "            'priority2': obj2['priority'], 'speed2': obj2['speed'],\n",
    "            'opacity2': obj2['opacity'], 'rotation2': obj2['rotation'],\n",
    "            'collision': collision(obj1, obj2)\n",
    "        }\n",
    "        \n",
    "        # Фильтруем только нужные колонки\n",
    "        filtered_row = {k: row_data[k] for k in selected_columns}\n",
    "        temp_df = pd.DataFrame([filtered_row])\n",
    "        df = pd.concat([df, temp_df], ignore_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1: 50 строк, 4 признаков\n",
      "Dataset 2: 50 строк, 7 признаков\n",
      "Dataset 3: 50 строк, 10 признаков\n",
      "Dataset 4: 200 строк, 4 признаков\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9740\\2956248099.py:43: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, temp_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 5: 200 строк, 7 признаков\n",
      "Dataset 6: 200 строк, 10 признаков\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9740\\2956248099.py:43: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, temp_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 7: 500 строк, 4 признаков\n",
      "Dataset 8: 500 строк, 7 признаков\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9740\\2956248099.py:43: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, temp_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 9: 500 строк, 10 признаков\n",
      "Dataset 10: 1000 строк, 4 признаков\n",
      "Dataset 11: 1000 строк, 7 признаков\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9740\\2956248099.py:43: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, temp_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 12: 1000 строк, 10 признаков\n"
     ]
    }
   ],
   "source": [
    "datasets = {}\n",
    "\n",
    "# Параметры размеров\n",
    "size_ranges = [50,200,500,1000]\n",
    "\n",
    "\n",
    "# Количество признаков\n",
    "feature_counts = [4, 7, 10]\n",
    "\n",
    "# Генерируем датасеты\n",
    "dataset_counter = 1\n",
    "for size_range in size_ranges:\n",
    "    for feature_count in feature_counts:\n",
    "        datasets[f'dataset_{dataset_counter}'] = generate_data(size_range, feature_count)\n",
    "        print(f\"Dataset {dataset_counter}: {size_range} строк, {feature_count} признаков\")\n",
    "        dataset_counter += 1\n",
    "\n",
    "# Пример сохранения датасетов в файлы\n",
    "for name, df in datasets.items():\n",
    "    df.to_csv(f\"{name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: потребление = 0.6000, Время обучения = 0.0101 сек\n",
      "Decision Tree: потребление = 0.4000, Время обучения = 0.0012 сек\n",
      "K-Nearest Neighbors: потребление = 0.4000, Время обучения = 0.0008 сек\n",
      "Naive Bayes: потребление = 0.8000, Время обучения = 0.0011 сек\n",
      "\n",
      "Три наиболее быстрых алгоритма с низким потреблением данных:\n",
      "- Naive Bayes: потребление = 0.8000, время = 0.0011 сек\n",
      "- Logistic Regression: потребление = 0.6000, время = 0.0101 сек\n",
      "- Decision Tree: потребление = 0.4000, время = 0.0012 сек\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# Предполагаем, что у нас есть один из ваших датасетов, например, dataset_1.csv\n",
    "df = pd.read_csv('dataset_1.csv')\n",
    "\n",
    "# Подготовка данных\n",
    "# Кодируем категориальные признаки\n",
    "le_figure1 = LabelEncoder()\n",
    "le_figure2 = LabelEncoder()\n",
    "df['figure1'] = le_figure1.fit_transform(df['figure1'])\n",
    "df['figure2'] = le_figure2.fit_transform(df['figure2'])\n",
    "\n",
    "# Если есть дополнительные категориальные признаки (color1, color2)\n",
    "if 'color1' in df.columns:\n",
    "    le_color1 = LabelEncoder()\n",
    "    le_color2 = LabelEncoder()\n",
    "    df['color1'] = le_color1.fit_transform(df['color1'])\n",
    "    df['color2'] = le_color2.fit_transform(df['color2'])\n",
    "\n",
    "# Разделяем признаки и целевую переменную\n",
    "X = df.drop('collision', axis=1)\n",
    "y = df['collision']\n",
    "\n",
    "# Разделяем на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Выбор 4 классических методов машинного обучения\n",
    "models = {\n",
    "    # Логистическая регрессия: \n",
    "    # - Простой и интерпретируемый метод\n",
    "    # - Хорошо работает с бинарной классификацией\n",
    "    # - Эффективен для линейно разделимых данных\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    \n",
    "    # Дерево решений:\n",
    "    # - Интуитивно понятен и легко интерпретируется\n",
    "    # - Может моделировать нелинейные зависимости\n",
    "    # - Хорошо подходит для смешанных типов данных\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=5),\n",
    "    \n",
    "    # k-ближайших соседей:\n",
    "    # - Простой и не требует предположений о распределении данных\n",
    "    # - Эффективен для задач с локальной структурой данных\n",
    "    # - Подходит для небольших и средних датасетов\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    \n",
    "    # Наивный Байес:\n",
    "    # - Очень быстрый и требует мало данных для обучения\n",
    "    # - Хорошо работает с независимыми признаками\n",
    "    # - Прост в реализации и эффективен для базовой классификации\n",
    "    'Naive Bayes': GaussianNB()\n",
    "}\n",
    "\n",
    "# Обучение и оценка моделей\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    results[name] = {'accuracy': accuracy, 'time': training_time}\n",
    "    \n",
    "    # Сохранение модели\n",
    "    with open(f'{name.lower().replace(\" \", \"_\")}_model.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    print(f\"{name}: потребление = {accuracy:.4f}, Время обучения = {training_time:.4f} сек\")\n",
    "\n",
    "# Выбор 3 наиболее быстрых алгоритмов с низким потреблением данных\n",
    "# Основываясь на характеристиках:\n",
    "# 1. Naive Bayes - минимальное время обучения, низкие требования к данным\n",
    "# 2. Logistic Regression - быстрая сходимость, работает с небольшими выборками\n",
    "# 3. Decision Tree - быстрое обучение на небольших данных, не требует сложной предобработки\n",
    "\n",
    "fastest_models = [\n",
    "    'Naive Bayes',\n",
    "    'Logistic Regression',\n",
    "    'Decision Tree'\n",
    "]\n",
    "\n",
    "print(\"\\nТри наиболее быстрых алгоритма с низким потреблением данных:\")\n",
    "for model_name in fastest_models:\n",
    "    print(f\"- {model_name}: потребление = {results[model_name]['accuracy']:.4f}, \"\n",
    "          f\"время = {results[model_name]['time']:.4f} сек\")\n",
    "\n",
    "# Пример загрузки сохраненной модели\n",
    "# with open('naive_bayes_model.pkl', 'rb') as f:\n",
    "#     loaded_model = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
